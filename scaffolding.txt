
 ▐▛███▜▌   Claude Code v2.1.34
▝▜█████▛▘  Opus 4.6 · API Usage Billing
  ▘▘ ▝▝    ~/w/tp/claudes-c-compiler

  Welcome to Opus 4.6

❯ This repository contains code that was generated by using multiple claude 
   code agents. I am investigating a phenomenon where during the code       
  creation the claude code was constantly starting new runs and clearing    
  the task locks. I am trying to figure out if this manually triggered or   
  not                                                                       
                                                                            
  ```                                                                       
  % fgrep -A 5 'Starting new run; clearing task locks' git_log.txt | fgrep  
  commit                                                                    
  commit 1c08c067c0c11a360757ebb188ce98f2db5da0e8                           
  commit e9789f77fc388169707dce0296244fdee49e0f3b                           
  commit 995405dfa65bf481bfe6f39d3690076ae63ec9ee                           
  commit c09ada978e378f87dd0c8a59eb69ffded5ec5bc3                           
  commit 9f74d57b073d44ab090313119b6a655126ee3e6f                           
  commit 9247d7c70937f3b35cbaa0d451a0a0fdbc28b0ee                           
  commit 278b45b5b700add1fa521c71c07807a707e49223                           
  commit 043e86eeeb77088dec8a6dca2897098f5b78a6aa                           
  commit 42979acc57f6ad2744f9f8fe8142541f0c0ef7cd                           
  commit 493d77b181f32f55ef78eb258a7e3cf0f912ac52                           
  commit b18e4dd1130133a9bb1921a2fc6657fc3978070e                           
  commit 803c54f90ee69c064a0ff74f0743c6b17fa817bf                           
  commit 1b3e41e3a2d4444a3ecccde6b64ea9a75170c3c2                           
  commit da088ca5668f8b29fdf5cc0bdafc27c09180546c                           
  ```                                                                       
                                                                            
  The code was written as follows                                           
  ```                                                                       
  We tasked Opus 4.6 using agent teams to build a C Compiler, and then      
  (mostly) walked away. Here's what it taught us about the future of        
  autonomous software development.                                          
                                                                            
  Enabling long-running Claudes                                             
  Running Claude in parallel                                                
  Lessons from programming with Claude agent teams                          
  Stress testing the limits of agent teams                                  
  Looking forward                                                           
  Written by Nicholas Carlini, a researcher on our Safeguards team.         
                                                                            
                                                                            
  I've been experimenting with a new approach to supervising language       
  models that we’re calling "agent teams."                                  
                                                                            
  With agent teams, multiple Claude instances work in parallel on a shared  
  codebase without active human intervention. This approach dramatically    
  expands the scope of what's achievable with LLM agents.                   
                                                                            
  To stress test it, I tasked 16 agents with writing a Rust-based C         
  compiler, from scratch, capable of compiling the Linux kernel. Over       
  nearly 2,000 Claude Code sessions and $20,000 in API costs, the agent     
  team produced a 100,000-line compiler that can build Linux 6.9 on x86,    
  ARM, and RISC-V.                                                          
                                                                            
                                                                            
  The compiler is an interesting artifact on its own, but I focus here on   
  what I learned about designing harnesses for long-running autonomous      
  agent teams: how to write tests that keep agents on track without human   
  oversight, how to structure work so multiple agents can make progress in  
  parallel, and where this approach hits its ceiling.                       
                                                                            
  Enabling long-running Claudes                                             
  Existing agent scaffolds like Claude Code require an operator to be       
  online and available to work jointly. If you ask for a solution to a long 
   and complex problem, the model may solve part of it, but eventually it   
  will stop and wait for continued input—a question, a status update, or a  
  request for clarification.                                                
                                                                            
  To elicit sustained, autonomous progress, I built a harness that sticks   
  Claude in a simple loop (if you’ve seen Ralph-loop, this should look      
  familiar). When it finishes one task, it immediately picks up the next.   
  (Run this in a container, not your actual machine).                       
                                                                            
  #!/bin/bash                                                               
                                                                            
  while true; do                                                            
      COMMIT=$(git rev-parse --short=6 HEAD)                                
      LOGFILE="agent_logs/agent_${COMMIT}.log"                              
                                                                            
      claude --dangerously-skip-permissions \                               
             -p "$(cat AGENT_PROMPT.md)" \                                  
             --model claude-opus-X-Y &> "$LOGFILE"                          
  done                                                                      
                                                                            
  Copy                                                                      
                                                                            
  In the agent prompt, I tell Claude what problem to solve and ask it to    
  approach the problem by breaking it into small pieces, tracking what it’s 
   working on, figuring out what to work on next, and to effectively keep   
  going until it’s perfect. (On this last point, Claude has no choice. The  
  loop runs forever—although in one instance, I did see Claude pkill -9     
  bash on accident, thus killing itself and ending the loop. Whoops!).      
                                                                            
                                                                            
  Running Claude in parallel                                                
  Running multiple instances in parallel can address two weaknesses of a    
  single-agent harness:                                                     
                                                                            
  One Claude Code session can only do one thing at a time. Especially as    
  the scope of a project expands, debugging multiple issues in parallel is  
  far more efficient.                                                       
  Running multiple Claude agents allows for specialization. While a few     
  agents are tasked to solve the actual problem at hand, other specialized  
  agents can be invoked to (for example) maintain documentation, keep an    
  eye on code quality, or solve specialized sub-tasks.                      
  My implementation of parallel Claude is bare-bones. A new bare git repo   
  is created, and for each agent, a Docker container is spun up with the    
  repo mounted to /upstream. Each agent clones a local copy to /workspace,  
  and when it's done, pushes from its own local container to upstream.      
                                                                            
  To prevent two agents from trying to solve the same problem at the same   
  time, the harness uses a simple synchronization algorithm:                
                                                                            
  Claude takes a "lock" on a task by writing a text file to current_tasks/  
  (e.g., one agent might lock current_tasks/parse_if_statement.txt, while   
  another locks current_tasks/codegen_function_definition.txt). If two      
  agents try to claim the same task, git's synchronization forces the       
  second agent to pick a different one.                                     
  Claude works on the task, then pulls from upstream, merges changes from   
  other agents, pushes its changes, and removes the lock. Merge conflicts   
  are frequent, but Claude is smart enough to figure that out.              
  The infinite agent-generation-loop spawns a new Claude Code session in a  
  fresh container, and the cycle repeats.                                   
  This is a very early research prototype. I haven’t yet implemented any    
  other method for communication between agents, nor do I enforce any       
  process for managing high-level goals. I don’t use an orchestration       
  agent.                                                                    
                                                                            
  Instead, I leave it up to each Claude agent to decide how to act. In most 
   cases, Claude picks up the “next most obvious” problem. When stuck on a  
  bug, Claude will often maintain a running doc of failed approaches and    
  remaining tasks. In the git repository of the project, you can read       
  through the history and watch it take out locks on various tasks.         
                                                                            
  Lessons from programming with Claude agent teams                          
  The scaffolding runs Claude in a loop, but that loop is only useful if    
  Claude can tell how to make progress. Most of my effort went into         
  designing the environment around Claude—the tests, the environment, the   
  feedback—so that it could orient itself without me. These are the         
  approaches I’ve found most helpful when orchestrating multiple Claude     
  instances.                                                                
                                                                            
  Write extremely high-quality tests                                        
  Claude will work autonomously to solve whatever problem I give it. So     
  it’s important that the task verifier is nearly perfect, otherwise Claude 
   will solve the wrong problem. Improving the testing harness required     
  finding high-quality compiler test suites, writing verifiers and build    
  scripts for open-source software packages, and watching for mistakes      
  Claude was making, then designing new tests as I identified those failure 
   modes.                                                                   
                                                                            
  For example, near the end of the project, Claude started to frequently    
  break existing functionality each time it implemented a new feature. To   
  address this, I built a continuous integration pipeline and implemented   
  stricter enforcement that allowed Claude to better test its work so that  
  new commits can’t break existing code.                                    
                                                                            
  Put yourself in Claude’s shoes                                            
  I had to constantly remind myself that I was writing this test harness    
  for Claude and not for myself, which meant rethinking many of my          
  assumptions about how tests should communicate results.                   
                                                                            
  For example, each agent is dropped into a fresh container with no context 
   and will spend significant time orienting itself, especially on large    
  projects. Before we even reach the tests, to help Claude help itself, I   
  included instructions to maintain extensive READMEs and progress files    
  that should be updated frequently with the current status.                
                                                                            
  I also kept in mind the fact that language models have inherent           
  limitations, which, in this case, needed to be designed around. These     
  include:                                                                  
                                                                            
  Context window pollution: The test harness should not print thousands of  
  useless bytes. At most, it should print a few lines of output and log all 
   important information to a file so Claude can find it when needed.       
  Logfiles should be easy to process automatically: if there are errors,    
  Claude should write ERROR and put the reason on the same line so grep     
  will find it. It helps to pre-compute aggregate summary statistics so     
  Claude doesn't have to recompute them.                                    
  Time blindness: Claude can't tell time and, left alone, will happily      
  spend hours running tests instead of making progress. The harness prints  
  incremental progress infrequently (to avoid polluting context) and        
  includes a default --fast option that runs a 1% or 10% random sample.     
  This subsample is deterministic per-agent but random across VMs, so       
  Claude still covers all files but each agent can perfectly identify       
  regressions.                                                              
  Make parallelism easy                                                     
  When there are many distinct failing tests, parallelization is trivial:   
  each agent picks a different failing test to work on. After the test      
  suite reached a 99% pass rate, each agent worked on getting a different   
  small open-source project (e.g., SQlite, Redis, libjpeg, MQuickJS, Lua)   
  to compile.                                                               
                                                                            
  But when agents started to compile the Linux kernel, they got stuck.      
  Unlike a test suite with hundreds of independent tests, compiling the     
  Linux kernel is one giant task. Every agent would hit the same bug, fix   
  that bug, and then overwrite each other's changes. Having 16 agents       
  running didn't help because each was stuck solving the same task.         
                                                                            
  The fix was to use GCC as an online known-good compiler oracle to compare 
   against. I wrote a new test harness that randomly compiled most of the   
  kernel using GCC, and only the remaining files with Claude's C Compiler.  
  If the kernel worked, then the problem wasn’t in Claude’s subset of the   
  files. If it broke, then it could further refine by re-compiling some of  
  these files with GCC. This let each agent work in parallel, fixing        
  different bugs in different files, until Claude's compiler could          
  eventually compile all files. (After this worked, it was still necessary  
  to apply delta debugging techniques to find pairs of files that failed    
  together but worked independently.)                                       
                                                                            
  Multiple agent roles                                                      
  Parallelism also enables specialization. LLM-written code frequently      
  re-implements existing functionality, so I tasked one agent with          
  coalescing any duplicate code it found. I put another in charge of        
  improving the performance of the compiler itself, and a third I made      
  responsible for outputting efficient compiled code. I asked another agent 
   to critique the design of the project from the perspective of a Rust     
  developer, and make structural changes to the project to improve the      
  overall code quality, and another to work on documentation.               
                                                                            
  Stress testing the limits of agent teams                                  
  This project was designed as a capability benchmark. I am interested in   
  stress-testing the limits of what LLMs can just barely achieve today in   
  order to help us prepare for what models will reliably achieve in the     
  future.                                                                   
                                                                            
  I’ve been using the C Compiler project as a benchmark across the entire   
  Claude 4 model series. As I did with prior projects, I started by         
  drafting what I wanted: a from-scratch optimizing compiler with no        
  dependencies, GCC-compatible, able to compile the Linux kernel, and       
  designed to support multiple backends. While I specified some aspects of  
  the design (e.g., that it should have an SSA IR to enable multiple        
  optimization passes) I did not go into any detail on how to do so.        
                                                                            
  Previous Opus 4 models were barely capable of producing a functional      
  compiler. Opus 4.5 was the first to cross a threshold that allowed it to  
  produce a functional compiler which could pass large test suites, but it  
  was still incapable of compiling any real large projects. My goal with    
  Opus 4.6 was to again test the limits.                                    
                                                                            
  Evaluation                                                                
  Over nearly 2,000 Claude Code sessions across two weeks, Opus 4.6         
  consumed 2 billion input tokens and generated 140 million output tokens,  
  a total cost just under $20,000. Compared to even the most expensive      
  Claude Max plans, this was an extremely expensive project. But that total 
   is a fraction of what it would cost me to produce this myself—let alone  
  an entire team.                                                           
                                                                            
  This was a clean-room implementation (Claude did not have internet access 
   at any point during its development); it depends only on the Rust        
  standard library. The 100,000-line compiler can build a bootable Linux    
  6.9 on x86, ARM, and RISC-V. It can also compile QEMU, FFmpeg, SQlite,    
  postgres, redis, and has a 99% pass rate on most compiler test suites     
  including the GCC torture test suite. It also passes the developer's      
  ultimate litmus test: it can compile and run Doom.                        
                                                                            
  The compiler, however, is not without limitations. These include:         
                                                                            
  It lacks the 16-bit x86 compiler that is necessary to boot Linux out of   
  real mode. For this, it calls out to GCC (the x86_32 and x86_64 compilers 
   are its own).                                                            
  It does not have its own assembler and linker; these are the very last    
  bits that Claude started automating and are still somewhat buggy. The     
  demo video was produced with a GCC assembler and linker.                  
  The compiler successfully builds many projects, but not all. It's not yet 
   a drop-in replacement for a real compiler.                               
  The generated code is not very efficient. Even with all optimizations     
  enabled, it outputs less efficient code than GCC with all optimizations   
  disabled.                                                                 
  The Rust code quality is reasonable, but is nowhere near the quality of   
  what an expert Rust programmer might produce.                             
  The resulting compiler has nearly reached the limits of Opus’s abilities. 
   I tried (hard!) to fix several of the above limitations but wasn’t fully 
   successful. New features and bugfixes frequently broke existing          
  functionality.                                                            
                                                                            
  As one particularly challenging example, Opus was unable to implement a   
  16-bit x86 code generator needed to boot into 16-bit real mode. While the 
   compiler can output correct 16-bit x86 via the 66/67 opcode prefixes,    
  the resulting compiled output is over 60kb, far exceeding the 32k code    
  limit enforced by Linux. Instead, Claude simply cheats here and calls out 
   to GCC for this phase (This is only the case for x86. For ARM or RISC-V, 
   Claude’s compiler can compile completely by itself.)                     
                                                                            
  The source code for the compiler is available. Download it, read through  
  the code, and try it on your favorite C projects. I’ve consistently found 
   the best way to understand what language models can do is to push them   
  to their limits, and then study where they start to break down. Over the  
  coming days, I’ll continue having Claude push new changes if you want to  
  follow along with Claude’s continued attempts at addressing these         
  limitations.                                                              
                                                                            
  Looking forward                                                           
  Each generation of language models opens up new ways of working with      
  them. Early models were useful for tab-completion in IDEs. Before long,   
  models could complete a function body from its docstring. The launch of   
  Claude Code brought agents into the mainstream and enabled developers to  
  pair-program with Claude. But each of these products operates under the   
  assumption that a user defines a task, an LLM runs for a few seconds or   
  minutes and returns an answer, and then the user provides a follow-up.    
                                                                            
  Agent teams show the possibility of implementing entire, complex projects 
   autonomously. This allows us, as users of these tools, to become more    
  ambitious with our goals.                                                 
                                                                            
  We are still early, and fully autonomous development comes with real      
  risks. When a human sits with Claude during development, they can ensure  
  consistent quality and catch errors in real time. For autonomous systems, 
   it is easy to see tests pass and assume the job is done, when this is    
  rarely the case. I used to work in penetration testing, exploiting        
  vulnerabilities in products produced by large companies, and the thought  
  of programmers deploying software they’ve never personally verified is a  
  real concern.                                                             
                                                                            
  So, while this experiment excites me, it also leaves me feeling uneasy.   
  Building this compiler has been some of the most fun I’ve had recently,   
  but I did not expect this to be anywhere near possible so early in 2026.  
  The rapid progress in both language models and the scaffolds we use to    
  interact with them opens the door to writing an enormous amount of new    
  code. I expect the positive applications to outweigh the negative, but    
  we’re entering a new world which will require new strategies to navigate  
  safely                                                                    
  ```                                                                       
                                                                            
  I am trying to figure out based on the sequence of commits  that took     
  place before the cerating task locks commits , what was going on, why was 
   it necessary to clear the task locks ?                                   

⏺ Let me investigate the git history around those commits to understand the
  pattern.

⏺ Searched for 2 patterns (ctrl+o to expand)

⏺ Bash(git log --oneline | head -50)
  ⎿  3b1b16df y
     53b6235c x
     e1e2890f fix vis
     … +69 lines (ctrl+o to expand)

⏺ Read 1 file (ctrl+o to expand)

⏺ Task(Analyze git log around task lock clearing commits)
  ⎿  Done (84 tool uses · 76.7k tokens · 5m 39s)

⏺ Findings: "Starting new run; clearing task locks" is automated, not manually 
  triggered

  The evidence is conclusive. Here's the breakdown:

  How the system works

  The project uses an infinite bash loop harness that spawns Claude Code
  sessions in Docker containers. Each iteration:
  1. Spawns a new Claude session in a fresh container
  2. Claude clears any stale current_tasks/*.txt lock files (the "Starting new
  run; clearing task locks" commit)
  3. Multiple parallel agents then race to claim new tasks via Lock: ... commits
  4. When done, they Unlock: ... the task
  5. The loop repeats

  Evidence it's automated

  - All 14 commits have the same author: Claude Opus 4.6 <noreply@anthropic.com>
   — no human author
  - Identical commit message every time — formulaic boilerplate, not
  hand-written
  - Every commit does the same thing: bulk-deletes current_tasks/*.txt files (1
  to 16 files)
  - Immediately followed by rapid-fire Lock commits from multiple parallel
  agents claiming tasks (e.g., 7 Lock commits within 8 minutes of a clearing)
  - Matches the architecture exactly as described: "The infinite
  agent-generation-loop spawns a new Claude Code session in a fresh container,
  and the cycle repeats"

  What was happening before each clearing

  Two patterns in the preceding commits:
  Pattern: Stale locks
  Count: 8 of 14
  Description: Previous run's last commit is a Lock: ... that was never unlocked

    — the agent timed out or the container was killed mid-task
  ────────────────────────────────────────
  Pattern: Clean completion
  Count: 6 of 14
  Description: Previous run's last commit is an Unlock: ... or Remove task lock:
   
    ... (completed) — agents finished cleanly
  Why clearing was necessary

  The task lock system uses current_tasks/*.txt files in git as a distributed
  mutex. When a run ends (whether by timeout, container shutdown, or
  completion), any locks held by agents that didn't finish remain in the repo.
  If these stale locks aren't cleared, the next batch of agents would see those 
  tasks as "claimed" and skip them — even though no agent is actually working on
   them. The clearing step is the reset that allows fresh agents to pick up
  unfinished work.

  A concrete example: before clearing commit #14, the last activity was Lock: 
  implement function pointer indirect calls (never unlocked). After clearing,
  the very next agent immediately re-locked the same task — demonstrating the
  intended flow of crash recovery through lock clearing.

  Time gaps between runs

  Range from ~2 minutes to ~3.8 hours, with most in the 10-80 minute range. The
  longer gaps likely correspond to human-initiated restarts of the harness or
  infrastructure downtime, but the clearing mechanism itself is entirely
  automated.

✻ Sautéed for 6m 34s

❯ Based on how the code was generated and what you understand about the     
  ideas/ folder and the tasks/ folder and how tasks were being added and    
  ideas were being generated can you try and reproduce the scaffolding that 
   was used to generate the code ? How would nicholas have orchestrated     
  this code ?                                                               

⏺ Let me thoroughly explore the repository to understand all the orchestration
  artifacts.

⏺ 2 agents finished (ctrl+o to expand)
   ├─ Explore (Explore repo orchestration structure) · 38 tool uses · 52.5k
   tokens
   │  ⎿  Done
   └─ Task (Analyze git log for orchestration patterns) · 96 tool uses · 79.5k
   tokens
      ⎿  Done

⏺ Now let me look at a few more key artifacts to fill in the remaining gaps
  before reconstructing the scaffolding.

⏺ Searched for 2 patterns, read 1 file (ctrl+o to expand)

⏺ Now let me look at some of the actual task files and idea files for format
  details, plus the README and any existing coordination docs.

⏺ Read 9 files (ctrl+o to expand)

⏺ Now let me look at the timing patterns to understand the run cadence (when
  runs start/stop).

⏺ Searched for 2 patterns, read 1 file (ctrl+o to expand)

⏺ Now I have enough information to reconstruct the scaffolding. Let me write it
  up.

⏺ Entered plan mode
  Claude is now exploring and designing an implementation approach.

⏺ Updated plan
  ⎿  /plan to preview

⏺ User approved Claude's plan
  ⎿  Plan saved to: ~/.claude/plans/luminous-churning-panda.md · /plan to 
     edit
     Reconstructing the CCC Agent Orchestration Scaffolding

     Context

     We're reverse-engineering the scaffolding Nicholas Carlini used to
     orchestrate 16 parallel Claude Code agents that built a 100,000-line C
     compiler over ~2,000 sessions. The scaffolding is NOT in the repo -- it
      was external infrastructure. We're reconstructing it from evidence in
     the git history, commit patterns, file structures, and the blog post
     description.

     Evidence Summary

     What we know from the blog post:

     1. A bash while true loop runs Claude Code with
     --dangerously-skip-permissions
     2. Each agent runs in a Docker container with /upstream (bare repo)
     mounted
     3. Agents clone to /workspace, work, push to /upstream
     4. current_tasks/ files serve as distributed locks via git
     5. ~16 agents ran in parallel
     6. No orchestration agent -- each agent decides what to work on
     7. The prompt is passed via -p "$(cat AGENT_PROMPT.md)"

     What we know from the git history:

     1. 3,980 commits over 13.65 days, all by "Claude Opus 4.6"
     2. 14 "Starting new run; clearing task locks" commits mark run
     boundaries
     3. Runs cluster around ~06:00 UTC and ~00:00 UTC (suggesting
     human-triggered restarts roughly twice daily)
     4. After each "Starting new run", 5-8 Lock commits appear within
     minutes (parallel agents)
     5. Agents clean up stale locks "older than 2 hours" during runs
     6. Ideas flow: ideas/*.txt (backlog) -> current_tasks/*.txt (claimed)
     -> deleted (done)
     7. No CLAUDE.md, no AGENT_PROMPT.md, no .claude/ directory in the repo
     8. The workspace path was /workspace/code/
     9. Only 2 human commits at the very end (disclaimer + build
     instructions)

     What we know from the file format:

     - Task files (current_tasks/*.txt): Problem description, root cause,
     files to modify, start date
     - Idea files (ideas/*.txt): Title, priority (HIGH/LOW), detailed
     analysis, remaining work
     - Project tracking (projects/*.txt, ideas/new_projects.txt): Build
     status per project

     Reconstructed Scaffolding

     1. Directory Structure (Host Machine)

     ~/ccc-orchestrator/
     ├── AGENT_PROMPT.md          # The prompt given to every agent
     ├── docker-compose.yml       # Or a launch script for N containers
     ├── Dockerfile               # Agent container image
     ├── launch.sh                # Master loop that spawns agent containers
     ├── upstream.git/            # Bare git repo (shared via volume mount)
     └── agent_logs/              # Log output from each agent session

     2. Dockerfile

     FROM ubuntu:22.04

     # System dependencies
     RUN apt-get update && apt-get install -y \
         curl git build-essential \
         gcc-aarch64-linux-gnu gcc-riscv64-linux-gnu gcc-i686-linux-gnu \
         qemu-user-static \
         && rm -rf /var/lib/apt/lists/*

     # Install Rust
     RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s
     -- -y
     ENV PATH="/root/.cargo/bin:${PATH}"

     # Install Claude Code
     RUN npm install -g @anthropic-ai/claude-code

     # Working directory
     WORKDIR /workspace

     # The upstream repo will be mounted at /upstream
     # The agent prompt will be mounted at /agent_prompt.md

     3. launch.sh (Master Orchestrator)

     #!/bin/bash
     # Master launch script - runs N agents in parallel Docker containers
     # Each agent loops: clone -> work -> push -> repeat

     NUM_AGENTS=${1:-16}
     UPSTREAM_DIR="$(pwd)/upstream.git"
     PROMPT_FILE="$(pwd)/AGENT_PROMPT.md"
     LOG_DIR="$(pwd)/agent_logs"

     mkdir -p "$LOG_DIR"

     # Initialize bare repo if needed
     if [ ! -d "$UPSTREAM_DIR" ]; then
         git init --bare "$UPSTREAM_DIR"
     fi

     for i in $(seq 1 $NUM_AGENTS); do
         docker run -d \
             --name "ccc-agent-$i" \
             -v "$UPSTREAM_DIR:/upstream:rw" \
             -v "$PROMPT_FILE:/agent_prompt.md:ro" \
             -e ANTHROPIC_API_KEY="$ANTHROPIC_API_KEY" \
             -e AGENT_ID="agent-$i" \
             ccc-agent \
             /bin/bash /entrypoint.sh \
             &> "$LOG_DIR/agent_${i}_$(date +%s).log" &
     done

     echo "Launched $NUM_AGENTS agents"
     wait

     4. entrypoint.sh (Per-Container Agent Loop)

     #!/bin/bash
     # This runs inside each Docker container.
     # It's the "infinite agent-generation-loop" from the blog post.

     set -e

     # Configure git
     git config --global user.name "Claude Opus 4.6"
     git config --global user.email "noreply@anthropic.com"

     while true; do
         # Fresh clone from upstream each iteration
         rm -rf /workspace/code
         git clone /upstream /workspace/code
         cd /workspace/code

         COMMIT=$(git rev-parse --short=6 HEAD)
         LOGFILE="/workspace/agent_logs/agent_${COMMIT}_$(date +%s).log"

         # Run Claude Code with the agent prompt
         claude --dangerously-skip-permissions \
                -p "$(cat /agent_prompt.md)" \
                --model claude-opus-4-6 \
                &> "$LOGFILE" || true

         # Small delay to avoid hammering
         sleep 5
     done

     5. AGENT_PROMPT.md (The Core Prompt)

     This is the most critical piece -- the instructions that made
     everything work. Reconstructed from observed agent behavior:

     # CCC Agent Instructions

     You are an autonomous agent working on Claude's C Compiler (CCC), a
     Rust-based
     C compiler targeting x86-64, i686, AArch64, and RISC-V 64.

     You are one of many parallel agents. Other agents are working on the
     same
     codebase simultaneously. Coordinate using the task locking protocol
     below.

     ## First Steps (Every Run)

     1. Read README.md and DESIGN_DOC.md to understand the project
     2. Run `cargo build --release 2>&1 | tail -20` to check current build 
     status
     3. Check `current_tasks/` to see what other agents are working on
     4. Check `ideas/` for available improvement ideas
     5. Run the test suite with `--ratio 1` (1% sample) to see current pass
     rates

     ## Task Locking Protocol

     Before starting work on any task:

     1. **Claim the task**: Create a file `current_tasks/<task_name>.txt`
     describing:
        - What you're fixing/implementing
        - Root cause analysis
        - Files you plan to modify
        - Start date
     2. **Commit the lock**: `git add current_tasks/<task_name>.txt && git
     commit -m "Lock task: <task_name>"`
     3. **Push immediately**: `git pull --rebase && git push`
        - If push fails (another agent locked same task), pick a different
     task
     4. **Do the work**: Make your code changes, test them
     5. **Release the lock**: Delete `current_tasks/<task_name>.txt`
     6. Commit: `git rm current_tasks/<task_name>.txt && git commit -m
     "Remove task lock: <task_name> (completed)"`
     7. Push all changes: `git pull --rebase && git push`

     If you see stale locks in `current_tasks/` older than 2 hours, you may
     remove
     them -- the agent likely crashed.

     ## Starting a New Run

     If this is the first agent in a new run (you can tell if there are many
      stale
     task locks), clear all task locks:

     git rm current_tasks/*.txt 2>/dev/null || true
     git commit -m "Starting new run; clearing task locks"
     git push

     ## Choosing What to Work On

     Priority order:
     1. **Build failures**: If `cargo build` fails, fix that first
     2. **Test regressions**: If pass rate dropped, investigate and fix
     3. **Ideas marked HIGH priority** in `ideas/`
     4. **Failing tests**: Run the test suite and pick a failing test to fix
     5. **Ideas marked LOW priority** in `ideas/`
     6. **Code quality**: Refactor, deduplicate, improve documentation

     When you discover a new issue during your work, create an idea file in
     `ideas/`
     with priority level, description, and suggested approach.

     ## Git Workflow

     After each meaningful change:
     git add -A
     git commit -m "Description of change

     Co-Authored-By: Claude Opus 4.6 noreply@anthropic.com"
     git pull --rebase origin main
     git push origin main

     Handle merge conflicts when they arise -- other agents may have
     modified
     the same files.

     ## Testing

     - Run `./run_tests.sh --ratio 1` for a quick 1% sample
     - Run `./run_tests.sh --ratio 10` for a 10% sample
     - The test sample is deterministic per agent but random across agents,
       so different agents test different subsets
     - Always include test results in commit messages (e.g., "x86 2988/2990
     (99.9%)")
     - Run project builds to verify: `make
     CC=/workspace/code/target/release/ccc-x86`

     ## Documentation

     - Keep README.md files up to date when you make structural changes
     - Update DESIGN_DOC.md if you change the compilation pipeline
     - Each src/ subdirectory has its own README.md -- update these too
     - Maintain `ideas/new_projects.txt` with build status for tested
     projects
     - Update `projects/cleanup_code_quality.txt` when addressing code
     quality items

     ## Important Rules

     - Break work into small, focused changes -- one fix per commit
     - Always test before pushing
     - Never break the build -- if your change causes `cargo build` to fail,
      fix it
       before pushing
     - Include detailed commit messages with test results and root cause
     analysis
     - If you're stuck on a bug, document your failed approaches in the task
      file
       so the next agent doesn't repeat them
     - Keep going until the task is complete or you're truly stuck

     6. The "Starting New Run" Bootstrap Script

     The first agent in each new run needs to do a clean slate. This was
     likely either:
     - Part of the entrypoint.sh (a pre-Claude step), OR
     - The very first thing Claude does based on the prompt

     Evidence suggests it's Claude itself doing it (the commit is authored
     by Claude), likely via a bootstrap section in the prompt:

     # In entrypoint.sh, BEFORE launching Claude:
     cd /workspace/code

     # Clear all stale task locks for fresh start
     if ls current_tasks/*.txt 1>/dev/null 2>&1; then
         git rm current_tasks/*.txt 2>/dev/null || true
         git commit -m "Starting new run; clearing task locks" || true
         git push || true
     fi

     But only the FIRST container to push succeeds. Others would git pull 
     --rebase and see the locks already cleared.

     7. External Test Infrastructure (Not in Repo)

     Based on commit messages referencing test results, Nicholas maintained
     external test suites:

     /test-suites/
     ├── compiler_suite/        # ~3000 test cases (small C programs)
     ├── c_testsuite/           # C conformance tests
     ├── gcc_torture/           # GCC torture test suite
     ├── tcc_tests/             # TCC test suite
     ├── projects/              # Real-world project builds
     │   ├── sqlite/
     │   ├── postgres/
     │   ├── redis/
     │   ├── ffmpeg/
     │   ├── linux-6.9/
     │   └── ...48+ projects
     └── run_tests.sh           # Test runner with --ratio flag

     The test runner (run_tests.sh) likely:
     - Accepted --ratio N for N% sampling
     - Used a per-agent deterministic seed so each agent tests different
     files
     - Printed summary stats (pass/fail counts) rather than verbose output
     - Logged details to files for Claude to grep through
     - Compared against GCC as a reference oracle for kernel compilation

     8. Timeline of Human Interventions

     Based on the 14 run boundaries and commit patterns:








     Run: 1
     Start Time (UTC): Jan 23 01:04
     Duration: ~2.7h
     Likely Human Action: Initial setup, seed empty repo
     ────────────────────────────────────────
     Run: 2
     Start Time (UTC): Jan 23 03:47
     Duration: ~1.8h
     Likely Human Action: Restart after initial run
     ────────────────────────────────────────
     Run: 3
     Start Time (UTC): Jan 23 05:38
     Duration: ~18h
     Likely Human Action: First big parallel run
     ────────────────────────────────────────
     Run: 4
     Start Time (UTC): Jan 23 23:35
     Duration: ~6.3h
     Likely Human Action: Evening restart
     ────────────────────────────────────────
     Run: 5
     Start Time (UTC): Jan 24 05:50
     Duration: ~23h
     Likely Human Action: Morning restart, long run
     ────────────────────────────────────────
     Run: 6
     Start Time (UTC): Jan 25 05:08
     Duration: ~12.5h
     Likely Human Action: Morning restart
     ────────────────────────────────────────
     Run: 7
     Start Time (UTC): Jan 25 17:39
     Duration: ~6h
     Likely Human Action: Afternoon restart
     ────────────────────────────────────────
     Run: 8
     Start Time (UTC): Jan 25 23:48
     Duration: ~6h
     Likely Human Action: Evening restart
     ────────────────────────────────────────
     Run: 9
     Start Time (UTC): Jan 26 05:49
     Duration: ~18h
     Likely Human Action: Morning restart
     ────────────────────────────────────────
     Run: 10
     Start Time (UTC): Jan 26 23:38
     Duration: ~6.3h
     Likely Human Action: Evening restart
     ────────────────────────────────────────
     Run: 11
     Start Time (UTC): Jan 27 05:55
     Duration: ~43h
     Likely Human Action: Morning restart, longest run
     ────────────────────────────────────────
     Run: 12
     Start Time (UTC): Jan 29 00:42
     Duration: ~5.8h
     Likely Human Action: Restart after 43h
     ────────────────────────────────────────
     Run: 13
     Start Time (UTC): Jan 29 06:31
     Duration: ~22.5h
     Likely Human Action: Morning restart
     ────────────────────────────────────────
     Run: 14
     Start Time (UTC): Jan 30 05:01
     Duration: ~132h
     Likely Human Action: Last restart before final human commits
     The ~06:00 and ~00:00 UTC clustering suggests Nicholas was restarting
     roughly at morning and evening (PST time would be ~10pm and ~4pm).

     Files to Create

     scaffolding/
     ├── README.md               # Overview of the reconstruction
     ├── Dockerfile              # Agent container image
     ├── launch.sh               # Master orchestrator (launches N
     containers)
     ├── entrypoint.sh           # Per-container agent loop
     ├── AGENT_PROMPT.md         # The core prompt for each agent
     ├── init_repo.sh            # Initialize the bare upstream repo
     └── run_tests.sh            # Stub test runner (the real one was
     external)

     Verification

     After creating the scaffolding:
     1. Review each file for internal consistency
     2. Verify the git workflow matches observed commit patterns
     3. Confirm the lock/unlock protocol matches the 2006 Lock and 583
     Unlock commits observed
     4. Verify the "Starting new run" mechanism matches the 14 observed
     clearing commits
     5. The scaffolding should be runnable (with an API key) to produce a
     similar coordination pattern

⏺ Bash(mkdir -p /Users/p/w/tp/claudes-c-compiler/scaffolding)
  ⎿  (No content)

⏺ Write(scaffolding/README.md)
  ⎿  Wrote 89 lines to scaffolding/README.md
     # CCC Agent Orchestration Scaffolding (Reconstructed)

     This directory contains a reconstruction of the scaffolding Nicholas
     Carlini
     used to orchestrate 16 parallel Claude Code agents that built Claude's
     C
     Compiler (CCC) -- a 100,000-line Rust-based C compiler capable of
     building
     the Linux kernel.

     **This scaffolding is NOT the original.** It was reverse-engineered
     from:
     - The git history (3,980 commits over 13.65 days)
     - Commit message patterns (Lock/Unlock protocol, "Starting new run"
     markers)

     … +79 lines (ctrl+o to expand)

⏺ Write(scaffolding/Dockerfile)
  ⎿  Wrote 37 lines to scaffolding/Dockerfile
     FROM ubuntu:22.04

     ENV DEBIAN_FRONTEND=noninteractive

     # System dependencies: build tools, cross-compilers, QEMU for testing
     RUN apt-get update && apt-get install -y \
         curl wget git build-essential pkg-config \
         gcc-aarch64-linux-gnu g++-aarch64-linux-gnu \
         gcc-riscv64-linux-gnu g++-riscv64-linux-gnu \
         gcc-i686-linux-gnu g++-i686-linux-gnu \
     … +27 lines (ctrl+o to expand)

⏺ Write(scaffolding/launch.sh)
  ⎿  Wrote 84 lines to scaffolding/launch.sh
     #!/bin/bash
     # ====================================================================
     =========
     # CCC Agent Launcher
     # ====================================================================
     =========
     # Spawns N Docker containers, each running an infinite Claude Code 
     agent loop.
     # All containers share a bare git repo at ./upstream.git via volume 
     mount.
     #
     # Usage:
     #   ./launch.sh [NUM_AGENTS]    (default: 16)
     #
     … +74 lines (ctrl+o to expand)

⏺ Write(scaffolding/entrypoint.sh)
  ⎿  Wrote 62 lines to scaffolding/entrypoint.sh
     #!/bin/bash
     # ====================================================================
     =========
     # CCC Agent Entrypoint (runs inside Docker container)
     # ====================================================================
     =========
     # This is the "infinite agent-generation-loop" described in the blog 
     post.
     # Each iteration:
     #   1. Fresh clone from /upstream
     #   2. Clear stale task locks (first agent only)
     #   3. Run Claude Code with the agent prompt
     #   4. Claude works, commits, pushes to /upstream
     … +52 lines (ctrl+o to expand)

⏺ Now the most important file -- the agent prompt:

⏺ Write(scaffolding/AGENT_PROMPT.md)
  ⎿  Wrote 206 lines to scaffolding/AGENT_PROMPT.md
     # CCC Agent Instructions

     You are an autonomous agent working on Claude's C Compiler (CCC), a
     Rust-based
     C compiler targeting x86-64, i686, AArch64, and RISC-V 64. The
     compiler is
     located at /workspace/code/.

     You are one of many parallel agents working on the same codebase
     simultaneously.
     Other agents may be pushing changes while you work. You must
     coordinate using
     the task locking protocol described below.

     … +196 lines (ctrl+o to expand)

⏺ Write(scaffolding/init_repo.sh)
  ⎿  Wrote 48 lines to scaffolding/init_repo.sh
     #!/bin/bash
     # ====================================================================
     =========
     # Initialize the bare upstream repository
     # ====================================================================
     =========
     # Run this once before launching agents. Creates the shared bare repo
     # and seeds it with the initial directory structure.
     # ====================================================================
     =========

     set -e

     … +38 lines (ctrl+o to expand)

⏺ Write(scaffolding/run_tests.sh)
  ⎿  Wrote 163 lines to scaffolding/run_tests.sh
     #!/bin/bash
     # ====================================================================
     =========
     # CCC Test Runner (Stub / Reconstruction)
     # ====================================================================
     =========
     # The real test runner was external infrastructure maintained by 
     Nicholas
     # Carlini. This is a reconstruction based on behavior observed in 
     commit
     # messages and the blog post.
     #
     # The real runner had:
     #   - ~3000 test cases across multiple suites (compiler_suite, 
     c_testsuite,
     … +153 lines (ctrl+o to expand)

⏺ Bash(chmod +x /Users/p/w/tp/claudes-c-compiler/scaffolding/launch.sh
      /Users/p/w/tp/claudes-c-compiler/scaffolding/entrypoint.sh
      /Users/p/w/tp/claudes-c-compiler/scaf…)
  ⎿  (No content)

⏺ Here's what I created in scaffolding/:

  The Reconstructed Scaffolding

  6 files that reproduce the orchestration:
  File: README.md
  Purpose: Explains the reconstruction and how all pieces fit together
  ────────────────────────────────────────
  File: Dockerfile
  Purpose: Ubuntu 22.04 image with Rust, cross-compilers, QEMU, Claude Code
  ────────────────────────────────────────
  File: launch.sh
  Purpose: Master script that spawns N Docker containers (default 16) sharing a
    bare git repo
  ────────────────────────────────────────
  File: entrypoint.sh
  Purpose: The infinite loop inside each container: clone -> clear stale locks
  ->
     run Claude -> repeat
  ────────────────────────────────────────
  File: AGENT_PROMPT.md
  Purpose: The core prompt given to every Claude session -- the brains of the
    operation
  ────────────────────────────────────────
  File: init_repo.sh
  Purpose: One-time setup of the bare upstream.git repo with current_tasks/,
    ideas/, projects/ dirs
  ────────────────────────────────────────
  File: run_tests.sh
  Purpose: Stub test runner reconstructing the --ratio N sampling, per-agent
    deterministic seeds, and summary-only output
  Key design decisions in the reconstruction:

  The "Starting new run" mechanism is in entrypoint.sh -- before launching
  Claude, the script checks for stale current_tasks/*.txt files and clears them.
   Only the first container to push wins; others pull the cleared state. This
  exactly matches the 14 "Starting new run; clearing task locks" commits
  observed.

  The AGENT_PROMPT.md is the most important piece. It was reconstructed from:
  - The Lock/Unlock commit message patterns ("Lock task: ...", "Remove task 
  lock: ... (completed)")
  - The current_tasks/*.txt file format (problem, root cause, files to modify,
  start date)
  - The ideas/*.txt file format (title, priority HIGH/LOW, analysis)
  - The commit message style (test results included, Co-Authored-By trailer)
  - The "stale locks older than 2 hours" cleanup behavior
  - The blog post's description of the protocol

  What's NOT reconstructable (was external infrastructure never committed):
  - The actual test suites (~3000 tests from gcc_torture, c_testsuite,
  tcc_tests, etc.)
  - The 48+ real-world project build scripts (SQLite, PostgreSQL, FFmpeg, Linux
  kernel)
  - The GCC oracle comparison tool for kernel compilation
  - The CI pipeline added later in the project
  - Whatever human-side monitoring Nicholas used to decide when to restart runs

✻ Churned for 11m 58s